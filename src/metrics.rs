//! Module de calcul de mÃ©triques de qualitÃ© OCR.
//!
//! Ce module fournit des outils pour Ã©valuer la qualitÃ© des rÃ©sultats OCR
//! en comparant le texte extrait avec un texte de rÃ©fÃ©rence attendu.
//!
//! Les mÃ©triques principales incluent :
//! - **CER** (Character Error Rate) : Taux d'erreur au niveau des caractÃ¨res
//! - **WER** (Word Error Rate) : Taux d'erreur au niveau des mots
//! - **Distance de Levenshtein** : Nombre minimal d'opÃ©rations pour transformer un texte en un autre
//!
//! Ces mÃ©triques permettent de :
//! - Mesurer l'efficacitÃ© de diffÃ©rentes configurations OCR
//! - Comparer l'impact des prÃ©traitements
//! - Identifier les configurations optimales pour diffÃ©rents types d'images

/// Type d'erreur identifiÃ© lors de la comparaison de textes.
///
/// Cette enum catÃ©gorise les diffÃ©rentes erreurs qui peuvent survenir
/// lors de l'analyse de la diffÃ©rence entre le texte OCR et le texte de rÃ©fÃ©rence.
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::TextError;
///
/// let error = TextError::Substitution {
///     position: 5,
///     expected: 'a',
///     found: 'o',
/// };
///
/// match error {
///     TextError::Substitution { position, expected, found } => {
///         println!("CaractÃ¨re '{}' remplacÃ© par '{}' Ã  la position {}", expected, found, position);
///     }
///     _ => {}
/// }
/// ```
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TextError {
    /// Un caractÃ¨re a Ã©tÃ© substituÃ© par un autre.
    ///
    /// Par exemple : "chat" â†’ "chot" (a â†’ o)
    Substitution {
        /// Position du caractÃ¨re dans le texte de rÃ©fÃ©rence.
        position: usize,
        /// CaractÃ¨re attendu.
        expected: char,
        /// CaractÃ¨re trouvÃ© dans le texte OCR.
        found: char,
    },

    /// Un caractÃ¨re manque dans le texte OCR.
    ///
    /// Par exemple : "chat" â†’ "cht" (manque 'a')
    Deletion {
        /// Position du caractÃ¨re manquant dans le texte de rÃ©fÃ©rence.
        position: usize,
        /// CaractÃ¨re qui manque.
        expected: char,
    },

    /// Un caractÃ¨re supplÃ©mentaire a Ã©tÃ© ajoutÃ© dans le texte OCR.
    ///
    /// Par exemple : "chat" â†’ "chaat" (ajout d'un 'a')
    Insertion {
        /// Position de l'insertion dans le texte OCR.
        position: usize,
        /// CaractÃ¨re insÃ©rÃ© Ã  tort.
        found: char,
    },

    /// Un mot entier est incorrect.
    ///
    /// Cette variante est utilisÃ©e pour les erreurs au niveau des mots
    /// lors du calcul du WER.
    WordError {
        /// Position du mot dans le texte de rÃ©fÃ©rence.
        word_position: usize,
        /// Mot attendu.
        expected: String,
        /// Mot trouvÃ© dans le texte OCR.
        found: String,
    },
}

impl TextError {
    /// Retourne la position de l'erreur.
    ///
    /// Pour les erreurs de caractÃ¨res (Substitution, Deletion, Insertion),
    /// retourne la position du caractÃ¨re. Pour WordError, retourne la position du mot.
    ///
    /// # Exemples
    ///
    /// ```
    /// use text_recognition::metrics::TextError;
    ///
    /// let error = TextError::Substitution {
    ///     position: 5,
    ///     expected: 'a',
    ///     found: 'o',
    /// };
    ///
    /// assert_eq!(error.position(), 5);
    /// ```
    pub fn position(&self) -> usize {
        match self {
            TextError::Substitution { position, .. } => *position,
            TextError::Deletion { position, .. } => *position,
            TextError::Insertion { position, .. } => *position,
            TextError::WordError { word_position, .. } => *word_position,
        }
    }

    /// Retourne une description textuelle de l'erreur.
    ///
    /// # Exemples
    ///
    /// ```
    /// use text_recognition::metrics::TextError;
    ///
    /// let error = TextError::Substitution {
    ///     position: 5,
    ///     expected: 'a',
    ///     found: 'o',
    /// };
    ///
    /// assert_eq!(error.description(), "Substitution: 'a' â†’ 'o' at position 5");
    /// ```
    pub fn description(&self) -> String {
        match self {
            TextError::Substitution {
                position,
                expected,
                found,
            } => format!(
                "Substitution: '{}' â†’ '{}' at position {}",
                expected, found, position
            ),
            TextError::Deletion { position, expected } => {
                format!("Deletion: '{}' missing at position {}", expected, position)
            }
            TextError::Insertion { position, found } => {
                format!("Insertion: '{}' added at position {}", found, position)
            }
            TextError::WordError {
                word_position,
                expected,
                found,
            } => format!(
                "Word error: '{}' â†’ '{}' at word position {}",
                expected, found, word_position
            ),
        }
    }
}

/// RÃ©sultats de la comparaison entre le texte OCR et le texte de rÃ©fÃ©rence.
///
/// Cette structure contient toutes les mÃ©triques calculÃ©es lors de la comparaison
/// d'un rÃ©sultat OCR avec un texte attendu.
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::OcrMetrics;
///
/// let metrics = OcrMetrics {
///     cer: 0.05,
///     wer: 0.10,
///     levenshtein_distance: 3,
///     reference_char_count: 60,
///     ocr_char_count: 58,
///     reference_word_count: 12,
///     ocr_word_count: 12,
///     exact_match: false,
/// };
///
/// println!("CER: {:.2}%", metrics.cer * 100.0);
/// ```
#[derive(Debug, Clone, PartialEq)]
pub struct OcrMetrics {
    /// Character Error Rate : taux d'erreur au niveau des caractÃ¨res (0.0 = parfait, 1.0 = 100% d'erreurs).
    pub cer: f64,

    /// Word Error Rate : taux d'erreur au niveau des mots (0.0 = parfait, 1.0 = 100% d'erreurs).
    pub wer: f64,

    /// Distance de Levenshtein : nombre minimal d'opÃ©rations (insertion, suppression, substitution)
    /// pour transformer le texte OCR en texte de rÃ©fÃ©rence.
    pub levenshtein_distance: usize,

    /// Nombre de caractÃ¨res dans le texte de rÃ©fÃ©rence.
    pub reference_char_count: usize,

    /// Nombre de caractÃ¨res dans le texte extrait par OCR.
    pub ocr_char_count: usize,

    /// Nombre de mots dans le texte de rÃ©fÃ©rence.
    pub reference_word_count: usize,

    /// Nombre de mots dans le texte extrait par OCR.
    pub ocr_word_count: usize,

    /// Indique si le texte OCR correspond exactement au texte de rÃ©fÃ©rence.
    pub exact_match: bool,
}

impl OcrMetrics {
    /// CrÃ©e une instance de `OcrMetrics` avec toutes les valeurs Ã  zÃ©ro.
    ///
    /// Utile comme valeur par dÃ©faut ou pour initialiser avant calcul.
    ///
    /// # Exemples
    ///
    /// ```
    /// use text_recognition::metrics::OcrMetrics;
    ///
    /// let metrics = OcrMetrics::zero();
    /// assert_eq!(metrics.cer, 0.0);
    /// assert_eq!(metrics.levenshtein_distance, 0);
    /// ```
    pub fn zero() -> Self {
        Self {
            cer: 0.0,
            wer: 0.0,
            levenshtein_distance: 0,
            reference_char_count: 0,
            ocr_char_count: 0,
            reference_word_count: 0,
            ocr_word_count: 0,
            exact_match: true,
        }
    }

    /// Retourne un pourcentage de prÃ©cision basÃ© sur le CER (1.0 - CER).
    ///
    /// # Exemples
    ///
    /// ```
    /// use text_recognition::metrics::OcrMetrics;
    ///
    /// let metrics = OcrMetrics {
    ///     cer: 0.05,
    ///     wer: 0.10,
    ///     levenshtein_distance: 3,
    ///     reference_char_count: 60,
    ///     ocr_char_count: 58,
    ///     reference_word_count: 12,
    ///     ocr_word_count: 12,
    ///     exact_match: false,
    /// };
    ///
    /// assert_eq!(metrics.accuracy(), 0.95);
    /// ```
    pub fn accuracy(&self) -> f64 {
        (1.0 - self.cer).max(0.0)
    }
}

impl Default for OcrMetrics {
    fn default() -> Self {
        Self::zero()
    }
}

/// Calcule la distance de Levenshtein entre deux chaÃ®nes de caractÃ¨res.
///
/// La distance de Levenshtein est le nombre minimal d'opÃ©rations nÃ©cessaires
/// pour transformer une chaÃ®ne en une autre. Les opÃ©rations autorisÃ©es sont :
/// - **Insertion** d'un caractÃ¨re
/// - **Suppression** d'un caractÃ¨re
/// - **Substitution** d'un caractÃ¨re par un autre
///
/// # Arguments
///
/// * `source` - La chaÃ®ne source (texte OCR)
/// * `target` - La chaÃ®ne cible (texte de rÃ©fÃ©rence)
///
/// # Retour
///
/// Le nombre minimal d'opÃ©rations nÃ©cessaires pour transformer `source` en `target`.
///
/// # Algorithme
///
/// Utilise la programmation dynamique avec une matrice de taille (n+1) Ã— (m+1)
/// oÃ¹ n et m sont les longueurs des deux chaÃ®nes.
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::levenshtein_distance;
///
/// // ChaÃ®nes identiques
/// assert_eq!(levenshtein_distance("chat", "chat"), 0);
///
/// // Une substitution
/// assert_eq!(levenshtein_distance("chat", "chot"), 1);
///
/// // Une insertion
/// assert_eq!(levenshtein_distance("chat", "chaat"), 1);
///
/// // Une suppression
/// assert_eq!(levenshtein_distance("chat", "cht"), 1);
///
/// // OpÃ©rations multiples
/// assert_eq!(levenshtein_distance("kitten", "sitting"), 3);
/// ```
///
/// # ComplexitÃ©
///
/// - **Temps** : O(n Ã— m) oÃ¹ n et m sont les longueurs des chaÃ®nes
/// - **Espace** : O(n Ã— m)
pub fn levenshtein_distance(source: &str, target: &str) -> usize {
    let source_chars: Vec<char> = source.chars().collect();
    let target_chars: Vec<char> = target.chars().collect();

    let source_len = source_chars.len();
    let target_len = target_chars.len();

    // Cas de base : si une des chaÃ®nes est vide
    if source_len == 0 {
        return target_len;
    }
    if target_len == 0 {
        return source_len;
    }

    // CrÃ©er une matrice (source_len + 1) Ã— (target_len + 1)
    let mut matrix = vec![vec![0usize; target_len + 1]; source_len + 1];

    // Initialiser la premiÃ¨re colonne (suppressions depuis source)
    #[allow(clippy::needless_range_loop)]
    for i in 0..=source_len {
        matrix[i][0] = i;
    }

    // Initialiser la premiÃ¨re ligne (insertions pour atteindre target)
    #[allow(clippy::needless_range_loop)]
    for j in 0..=target_len {
        matrix[0][j] = j;
    }

    // Remplir la matrice
    for i in 1..=source_len {
        for j in 1..=target_len {
            // CoÃ»t de substitution : 0 si les caractÃ¨res sont identiques, 1 sinon
            let substitution_cost = if source_chars[i - 1] == target_chars[j - 1] {
                0
            } else {
                1
            };

            matrix[i][j] = std::cmp::min(
                std::cmp::min(
                    matrix[i - 1][j] + 1, // Suppression
                    matrix[i][j - 1] + 1, // Insertion
                ),
                matrix[i - 1][j - 1] + substitution_cost, // Substitution
            );
        }
    }

    // La distance est dans la derniÃ¨re cellule
    matrix[source_len][target_len]
}

/// Calcule le CER (Character Error Rate) entre le texte OCR et le texte de rÃ©fÃ©rence.
///
/// Le CER est le taux d'erreur au niveau des caractÃ¨res, calculÃ© comme le rapport
/// entre la distance de Levenshtein et le nombre de caractÃ¨res dans le texte de rÃ©fÃ©rence.
///
/// **Formule** : CER = distance_levenshtein / nombre_caractÃ¨res_rÃ©fÃ©rence
///
/// # Arguments
///
/// * `ocr_text` - Le texte extrait par OCR
/// * `reference_text` - Le texte de rÃ©fÃ©rence attendu
///
/// # Retour
///
/// Un nombre flottant entre 0.0 et potentiellement > 1.0 :
/// - **0.0** : Textes identiques (aucune erreur)
/// - **< 1.0** : PrÃ©sence d'erreurs, mais moins d'opÃ©rations que de caractÃ¨res de rÃ©fÃ©rence
/// - **1.0** : Nombre d'erreurs Ã©gal au nombre de caractÃ¨res de rÃ©fÃ©rence
/// - **> 1.0** : Plus d'erreurs que de caractÃ¨res de rÃ©fÃ©rence (cas rare, nombreuses insertions)
///
/// # Cas particuliers
///
/// - Si le texte de rÃ©fÃ©rence est vide, retourne 0.0 si l'OCR est aussi vide, sinon 1.0
/// - Si les deux textes sont vides, retourne 0.0 (considÃ©rÃ© comme une correspondance parfaite)
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::calculate_cer;
///
/// // Textes identiques
/// let cer = calculate_cer("hello world", "hello world");
/// assert_eq!(cer, 0.0);
///
/// // Une erreur sur 11 caractÃ¨res
/// let cer = calculate_cer("hallo world", "hello world");
/// assert!((cer - 0.0909).abs() < 0.001); // â‰ˆ 1/11 = 0.0909
///
/// // Texte complÃ¨tement diffÃ©rent
/// let cer = calculate_cer("abc", "xyz");
/// assert_eq!(cer, 1.0); // 3 erreurs sur 3 caractÃ¨res
/// ```
pub fn calculate_cer(ocr_text: &str, reference_text: &str) -> f64 {
    let reference_len = reference_text.chars().count();

    // Cas particulier : texte de rÃ©fÃ©rence vide
    if reference_len == 0 {
        let ocr_len = ocr_text.chars().count();
        return if ocr_len == 0 { 0.0 } else { 1.0 };
    }

    let distance = levenshtein_distance(ocr_text, reference_text);
    distance as f64 / reference_len as f64
}

/// Calcule le WER (Word Error Rate) entre le texte OCR et le texte de rÃ©fÃ©rence.
///
/// Le WER est le taux d'erreur au niveau des mots, calculÃ© comme le rapport
/// entre la distance de Levenshtein au niveau des mots et le nombre de mots
/// dans le texte de rÃ©fÃ©rence.
///
/// **Formule** : WER = distance_levenshtein_mots / nombre_mots_rÃ©fÃ©rence
///
/// Les mots sont dÃ©finis comme des sÃ©quences de caractÃ¨res non-blancs sÃ©parÃ©es
/// par des espaces blancs.
///
/// # Arguments
///
/// * `ocr_text` - Le texte extrait par OCR
/// * `reference_text` - Le texte de rÃ©fÃ©rence attendu
///
/// # Retour
///
/// Un nombre flottant entre 0.0 et potentiellement > 1.0 :
/// - **0.0** : Tous les mots sont identiques
/// - **< 1.0** : PrÃ©sence d'erreurs, mais moins d'opÃ©rations que de mots de rÃ©fÃ©rence
/// - **1.0** : Nombre d'erreurs Ã©gal au nombre de mots de rÃ©fÃ©rence
/// - **> 1.0** : Plus d'erreurs que de mots de rÃ©fÃ©rence (cas rare)
///
/// # Cas particuliers
///
/// - Si le texte de rÃ©fÃ©rence est vide, retourne 0.0 si l'OCR est aussi vide, sinon 1.0
/// - Si les deux textes sont vides, retourne 0.0
/// - Les espaces multiples sont normalisÃ©s (traitÃ©s comme un seul sÃ©parateur)
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::calculate_wer;
///
/// // Textes identiques
/// let wer = calculate_wer("hello world", "hello world");
/// assert_eq!(wer, 0.0);
///
/// // Un mot diffÃ©rent sur 2
/// let wer = calculate_wer("hello universe", "hello world");
/// assert_eq!(wer, 0.5); // 1 erreur sur 2 mots
///
/// // Un mot manquant
/// let wer = calculate_wer("hello", "hello world");
/// assert_eq!(wer, 0.5); // 1 suppression sur 2 mots
///
/// // Un mot ajoutÃ©
/// let wer = calculate_wer("hello big world", "hello world");
/// assert_eq!(wer, 0.5); // 1 insertion sur 2 mots
/// ```
///
/// # Note
///
/// Le WER utilise l'algorithme de Levenshtein au niveau des mots entiers,
/// donc mÃªme une petite diffÃ©rence dans un mot (ex: "hello" vs "helo")
/// compte comme une erreur complÃ¨te.
pub fn calculate_wer(ocr_text: &str, reference_text: &str) -> f64 {
    // Diviser en mots (sÃ©quences non-blanches)
    let reference_words: Vec<&str> = reference_text.split_whitespace().collect();
    let ocr_words: Vec<&str> = ocr_text.split_whitespace().collect();

    let reference_word_count = reference_words.len();

    // Cas particulier : texte de rÃ©fÃ©rence vide
    if reference_word_count == 0 {
        let ocr_word_count = ocr_words.len();
        return if ocr_word_count == 0 { 0.0 } else { 1.0 };
    }

    // Calculer la distance de Levenshtein au niveau des mots
    let distance = word_levenshtein_distance(&ocr_words, &reference_words);
    distance as f64 / reference_word_count as f64
}

/// Calcule la distance de Levenshtein entre deux sÃ©quences de mots.
///
/// Similaire Ã  `levenshtein_distance` mais opÃ¨re sur des mots entiers
/// plutÃ´t que sur des caractÃ¨res individuels.
///
/// # Arguments
///
/// * `source` - SÃ©quence de mots source (texte OCR)
/// * `target` - SÃ©quence de mots cible (texte de rÃ©fÃ©rence)
///
/// # Retour
///
/// Le nombre minimal d'opÃ©rations (insertion, suppression, substitution de mots)
/// nÃ©cessaires pour transformer `source` en `target`.
fn word_levenshtein_distance(source: &[&str], target: &[&str]) -> usize {
    let source_len = source.len();
    let target_len = target.len();

    // Cas de base : si une des sÃ©quences est vide
    if source_len == 0 {
        return target_len;
    }
    if target_len == 0 {
        return source_len;
    }

    // CrÃ©er une matrice (source_len + 1) Ã— (target_len + 1)
    let mut matrix = vec![vec![0usize; target_len + 1]; source_len + 1];

    // Initialiser la premiÃ¨re colonne (suppressions depuis source)
    #[allow(clippy::needless_range_loop)]
    for i in 0..=source_len {
        matrix[i][0] = i;
    }

    // Initialiser la premiÃ¨re ligne (insertions pour atteindre target)
    #[allow(clippy::needless_range_loop)]
    for j in 0..=target_len {
        matrix[0][j] = j;
    }

    // Remplir la matrice
    for i in 1..=source_len {
        for j in 1..=target_len {
            // CoÃ»t de substitution : 0 si les mots sont identiques, 1 sinon
            let substitution_cost = if source[i - 1] == target[j - 1] { 0 } else { 1 };

            matrix[i][j] = std::cmp::min(
                std::cmp::min(
                    matrix[i - 1][j] + 1, // Suppression
                    matrix[i][j - 1] + 1, // Insertion
                ),
                matrix[i - 1][j - 1] + substitution_cost, // Substitution
            );
        }
    }

    // La distance est dans la derniÃ¨re cellule
    matrix[source_len][target_len]
}

/// Compare un rÃ©sultat OCR avec un texte de rÃ©fÃ©rence et calcule toutes les mÃ©triques.
///
/// Cette fonction effectue une analyse complÃ¨te de la qualitÃ© d'un rÃ©sultat OCR
/// en calculant le CER, le WER, la distance de Levenshtein, et en comptant les
/// caractÃ¨res et mots dans les deux textes.
///
/// # Arguments
///
/// * `ocr_text` - Le texte extrait par OCR
/// * `reference_text` - Le texte de rÃ©fÃ©rence attendu
///
/// # Retour
///
/// Une structure `OcrMetrics` contenant toutes les mÃ©triques calculÃ©es :
/// - `cer` : Character Error Rate
/// - `wer` : Word Error Rate
/// - `levenshtein_distance` : Distance de Levenshtein au niveau des caractÃ¨res
/// - `reference_char_count` : Nombre de caractÃ¨res dans la rÃ©fÃ©rence
/// - `ocr_char_count` : Nombre de caractÃ¨res dans le texte OCR
/// - `reference_word_count` : Nombre de mots dans la rÃ©fÃ©rence
/// - `ocr_word_count` : Nombre de mots dans le texte OCR
/// - `exact_match` : `true` si les textes sont identiques
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::compare_ocr_result;
///
/// // Textes identiques
/// let metrics = compare_ocr_result("hello world", "hello world");
/// assert_eq!(metrics.cer, 0.0);
/// assert_eq!(metrics.wer, 0.0);
/// assert!(metrics.exact_match);
///
/// // Texte avec une erreur
/// let metrics = compare_ocr_result("helo world", "hello world");
/// assert!(metrics.cer > 0.0);
/// assert!(metrics.wer > 0.0);
/// assert!(!metrics.exact_match);
/// assert_eq!(metrics.levenshtein_distance, 1);
/// ```
///
/// # Utilisation
///
/// Cette fonction est typiquement utilisÃ©e aprÃ¨s une extraction OCR pour Ã©valuer
/// la qualitÃ© du rÃ©sultat par rapport Ã  un texte de rÃ©fÃ©rence connu :
///
/// ```no_run
/// use text_recognition::ocr::OcrEngine;
/// use text_recognition::config::OcrConfig;
/// use text_recognition::metrics::compare_ocr_result;
/// use std::path::Path;
///
/// # fn main() -> anyhow::Result<()> {
/// let mut engine = OcrEngine::new(OcrConfig::default())?;
/// let ocr_text = engine.extract_text_from_file(Path::new("test.png"))?;
/// let reference = "Expected text content";
///
/// let metrics = compare_ocr_result(&ocr_text, reference);
/// println!("CER: {:.2}%", metrics.cer * 100.0);
/// println!("WER: {:.2}%", metrics.wer * 100.0);
/// println!("Accuracy: {:.2}%", metrics.accuracy() * 100.0);
/// # Ok(())
/// # }
/// ```
pub fn compare_ocr_result(ocr_text: &str, reference_text: &str) -> OcrMetrics {
    // Calculer la distance de Levenshtein
    let levenshtein_distance = levenshtein_distance(ocr_text, reference_text);

    // Compter les caractÃ¨res
    let reference_char_count = reference_text.chars().count();
    let ocr_char_count = ocr_text.chars().count();

    // Compter les mots
    let reference_word_count = reference_text.split_whitespace().count();
    let ocr_word_count = ocr_text.split_whitespace().count();

    // Calculer le CER
    let cer = calculate_cer(ocr_text, reference_text);

    // Calculer le WER
    let wer = calculate_wer(ocr_text, reference_text);

    // VÃ©rifier si c'est un match exact
    let exact_match = ocr_text == reference_text;

    OcrMetrics {
        cer,
        wer,
        levenshtein_distance,
        reference_char_count,
        ocr_char_count,
        reference_word_count,
        ocr_word_count,
        exact_match,
    }
}

/// GÃ©nÃ¨re un rapport dÃ©taillÃ© des diffÃ©rences entre le texte OCR et le texte de rÃ©fÃ©rence.
///
/// Cette fonction produit un rapport formatÃ© en texte qui prÃ©sente :
/// - Les mÃ©triques globales (CER, WER, distance de Levenshtein)
/// - Les statistiques de caractÃ¨res et de mots
/// - Une comparaison cÃ´te Ã  cÃ´te des textes
/// - Un rÃ©sumÃ© de la qualitÃ©
///
/// # Arguments
///
/// * `ocr_text` - Le texte extrait par OCR
/// * `reference_text` - Le texte de rÃ©fÃ©rence attendu
///
/// # Retour
///
/// Une chaÃ®ne de caractÃ¨res contenant le rapport formatÃ©, prÃªt Ã  Ãªtre affichÃ©
/// ou Ã©crit dans un fichier.
///
/// # Format du rapport
///
/// Le rapport contient les sections suivantes :
/// 1. **En-tÃªte** : Titre du rapport
/// 2. **MÃ©triques** : CER, WER, distance de Levenshtein, prÃ©cision
/// 3. **Statistiques** : Nombre de caractÃ¨res et mots dans chaque texte
/// 4. **Comparaison** : Affichage des deux textes pour comparaison visuelle
/// 5. **RÃ©sumÃ©** : Ã‰valuation qualitative du rÃ©sultat (Excellent, Bon, Moyen, Faible)
///
/// # Exemples
///
/// ```
/// use text_recognition::metrics::generate_diff_report;
///
/// let ocr = "hello world";
/// let reference = "hello world";
/// let report = generate_diff_report(ocr, reference);
/// println!("{}", report);
/// ```
///
/// Exemple de sortie pour un texte avec erreurs :
///
/// ```text
/// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
///                    OCR COMPARISON REPORT
/// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
///
/// METRICS:
/// --------
/// Character Error Rate (CER): 9.09%
/// Word Error Rate (WER):      50.00%
/// Levenshtein Distance:       1
/// Accuracy:                   90.91%
///
/// STATISTICS:
/// -----------
/// Reference: 11 characters, 2 words
/// OCR:       10 characters, 2 words
///
/// COMPARISON:
/// -----------
/// Reference: "hello world"
/// OCR:       "helo world"
///
/// SUMMARY:
/// --------
/// Quality: Good (minor errors)
/// Match:   Not exact
/// ```
///
/// # Utilisation
///
/// Cette fonction est utile pour :
/// - DÃ©boguer les problÃ¨mes d'OCR
/// - GÃ©nÃ©rer des rapports de test
/// - Comparer diffÃ©rentes configurations
/// - Documenter la qualitÃ© des rÃ©sultats
///
/// ```no_run
/// use text_recognition::ocr::OcrEngine;
/// use text_recognition::config::OcrConfig;
/// use text_recognition::metrics::generate_diff_report;
/// use std::path::Path;
/// use std::fs;
///
/// # fn main() -> anyhow::Result<()> {
/// let mut engine = OcrEngine::new(OcrConfig::default())?;
/// let ocr_text = engine.extract_text_from_file(Path::new("test.png"))?;
/// let reference = fs::read_to_string("test_expected.txt")?;
///
/// let report = generate_diff_report(&ocr_text, &reference);
/// fs::write("report.txt", report)?;
/// # Ok(())
/// # }
/// ```
pub fn generate_diff_report(ocr_text: &str, reference_text: &str) -> String {
    // Calculer les mÃ©triques
    let metrics = compare_ocr_result(ocr_text, reference_text);

    // DÃ©terminer la qualitÃ© du rÃ©sultat
    let quality = if metrics.exact_match {
        "Perfect (exact match)"
    } else if metrics.cer < 0.05 {
        "Excellent (< 5% error)"
    } else if metrics.cer < 0.15 {
        "Good (< 15% error)"
    } else if metrics.cer < 0.30 {
        "Fair (< 30% error)"
    } else {
        "Poor (â‰¥ 30% error)"
    };

    // Construire le rapport
    let mut report = String::new();

    // En-tÃªte
    report.push_str("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    report.push_str("                   OCR COMPARISON REPORT\n");
    report.push_str("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");

    // MÃ©triques
    report.push_str("METRICS:\n");
    report.push_str("--------\n");
    report.push_str(&format!(
        "Character Error Rate (CER): {:.2}%\n",
        metrics.cer * 100.0
    ));
    report.push_str(&format!(
        "Word Error Rate (WER):      {:.2}%\n",
        metrics.wer * 100.0
    ));
    report.push_str(&format!(
        "Levenshtein Distance:       {}\n",
        metrics.levenshtein_distance
    ));
    report.push_str(&format!(
        "Accuracy:                   {:.2}%\n",
        metrics.accuracy() * 100.0
    ));

    // Statistiques
    report.push_str("\nSTATISTICS:\n");
    report.push_str("-----------\n");
    report.push_str(&format!(
        "Reference: {} characters, {} words\n",
        metrics.reference_char_count, metrics.reference_word_count
    ));
    report.push_str(&format!(
        "OCR:       {} characters, {} words\n",
        metrics.ocr_char_count, metrics.ocr_word_count
    ));

    // Comparaison
    report.push_str("\nCOMPARISON:\n");
    report.push_str("-----------\n");

    // Limiter la longueur des textes affichÃ©s pour la lisibilitÃ©
    let max_display_len = 200;
    let ref_display = if reference_text.len() > max_display_len {
        format!("{}... (truncated)", &reference_text[..max_display_len])
    } else {
        reference_text.to_string()
    };
    let ocr_display = if ocr_text.len() > max_display_len {
        format!("{}... (truncated)", &ocr_text[..max_display_len])
    } else {
        ocr_text.to_string()
    };

    report.push_str(&format!("Reference: \"{}\"\n", ref_display));
    report.push_str(&format!("OCR:       \"{}\"\n", ocr_display));

    // RÃ©sumÃ©
    report.push_str("\nSUMMARY:\n");
    report.push_str("--------\n");
    report.push_str(&format!("Quality: {}\n", quality));
    report.push_str(&format!(
        "Match:   {}\n",
        if metrics.exact_match {
            "Exact"
        } else {
            "Not exact"
        }
    ));

    report.push_str("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    report
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_levenshtein_identical_strings() {
        assert_eq!(levenshtein_distance("hello", "hello"), 0);
        assert_eq!(levenshtein_distance("", ""), 0);
        assert_eq!(levenshtein_distance("a", "a"), 0);
    }

    #[test]
    fn test_levenshtein_empty_strings() {
        assert_eq!(levenshtein_distance("", "hello"), 5);
        assert_eq!(levenshtein_distance("hello", ""), 5);
        assert_eq!(levenshtein_distance("", ""), 0);
    }

    #[test]
    fn test_levenshtein_single_substitution() {
        assert_eq!(levenshtein_distance("chat", "chot"), 1);
        assert_eq!(levenshtein_distance("hello", "hallo"), 1);
    }

    #[test]
    fn test_levenshtein_single_insertion() {
        assert_eq!(levenshtein_distance("chat", "chaat"), 1);
        assert_eq!(levenshtein_distance("helo", "hello"), 1);
    }

    #[test]
    fn test_levenshtein_single_deletion() {
        assert_eq!(levenshtein_distance("chat", "cht"), 1);
        assert_eq!(levenshtein_distance("hello", "hllo"), 1);
    }

    #[test]
    fn test_levenshtein_multiple_operations() {
        // kitten â†’ sitting : 3 opÃ©rations
        // k â†’ s (substitution)
        // e â†’ i (substitution)
        // + t + g (2 insertions)
        assert_eq!(levenshtein_distance("kitten", "sitting"), 3);

        assert_eq!(levenshtein_distance("saturday", "sunday"), 3);
    }

    #[test]
    fn test_levenshtein_completely_different() {
        assert_eq!(levenshtein_distance("abc", "xyz"), 3);
    }

    #[test]
    fn test_levenshtein_unicode() {
        assert_eq!(levenshtein_distance("cafÃ©", "cafÃ©"), 0);
        assert_eq!(levenshtein_distance("cafÃ©", "cafe"), 1);
        assert_eq!(levenshtein_distance("ğŸ±", "ğŸ¶"), 1);
    }

    #[test]
    fn test_levenshtein_case_sensitive() {
        assert_eq!(levenshtein_distance("Hello", "hello"), 1);
        assert_eq!(levenshtein_distance("HELLO", "hello"), 5);
    }

    #[test]
    fn test_calculate_cer_identical_texts() {
        assert_eq!(calculate_cer("hello world", "hello world"), 0.0);
        assert_eq!(calculate_cer("", ""), 0.0);
        assert_eq!(calculate_cer("test", "test"), 0.0);
    }

    #[test]
    fn test_calculate_cer_empty_reference() {
        // RÃ©fÃ©rence vide, OCR vide : match parfait
        assert_eq!(calculate_cer("", ""), 0.0);

        // RÃ©fÃ©rence vide, OCR non vide : erreur complÃ¨te
        assert_eq!(calculate_cer("something", ""), 1.0);
    }

    #[test]
    fn test_calculate_cer_empty_ocr() {
        // OCR vide, rÃ©fÃ©rence non vide : 100% d'erreur
        let cer = calculate_cer("", "hello");
        assert_eq!(cer, 1.0); // 5 suppressions sur 5 caractÃ¨res
    }

    #[test]
    fn test_calculate_cer_single_error() {
        // 1 erreur sur 11 caractÃ¨res
        let cer = calculate_cer("hallo world", "hello world");
        assert!((cer - 1.0 / 11.0).abs() < 0.001);
    }

    #[test]
    fn test_calculate_cer_multiple_errors() {
        // "kitten" (OCR) vs "sitting" (rÃ©fÃ©rence) : 3 erreurs sur 7 caractÃ¨res
        let cer = calculate_cer("kitten", "sitting");
        assert!((cer - 3.0 / 7.0).abs() < 0.001); // â‰ˆ 0.4286
    }

    #[test]
    fn test_calculate_cer_completely_wrong() {
        // Texte complÃ¨tement diffÃ©rent : 100% d'erreur
        let cer = calculate_cer("abc", "xyz");
        assert_eq!(cer, 1.0); // 3 erreurs sur 3 caractÃ¨res
    }

    #[test]
    fn test_calculate_cer_more_than_100_percent() {
        // OCR beaucoup plus long que la rÃ©fÃ©rence : CER > 1.0
        let cer = calculate_cer("aaaaaaaaaa", "a");
        assert_eq!(cer, 9.0); // 9 insertions sur 1 caractÃ¨re de rÃ©fÃ©rence
    }

    #[test]
    fn test_calculate_cer_unicode() {
        // Test avec caractÃ¨res Unicode
        let cer = calculate_cer("cafÃ©", "cafÃ©");
        assert_eq!(cer, 0.0);

        // 1 erreur (Ã© â†’ e) sur 4 caractÃ¨res
        let cer = calculate_cer("cafe", "cafÃ©");
        assert_eq!(cer, 0.25); // 1/4
    }

    #[test]
    fn test_calculate_cer_case_sensitive() {
        // La casse compte : "Hello" vs "hello" = 1 erreur sur 5 caractÃ¨res
        let cer = calculate_cer("Hello", "hello");
        assert_eq!(cer, 0.2); // 1/5
    }

    #[test]
    fn test_calculate_cer_whitespace() {
        // Les espaces comptent
        let cer = calculate_cer("helloworld", "hello world");
        assert!((cer - 1.0 / 11.0).abs() < 0.001); // 1 suppression d'espace
    }

    #[test]
    fn test_calculate_wer_identical_texts() {
        assert_eq!(calculate_wer("hello world", "hello world"), 0.0);
        assert_eq!(calculate_wer("", ""), 0.0);
        assert_eq!(calculate_wer("one two three", "one two three"), 0.0);
    }

    #[test]
    fn test_calculate_wer_empty_reference() {
        // RÃ©fÃ©rence vide, OCR vide : match parfait
        assert_eq!(calculate_wer("", ""), 0.0);

        // RÃ©fÃ©rence vide, OCR non vide : erreur complÃ¨te
        assert_eq!(calculate_wer("hello world", ""), 1.0);
    }

    #[test]
    fn test_calculate_wer_empty_ocr() {
        // OCR vide, rÃ©fÃ©rence non vide : 100% d'erreur
        let wer = calculate_wer("", "hello world");
        assert_eq!(wer, 1.0); // 2 suppressions de mots sur 2 mots
    }

    #[test]
    fn test_calculate_wer_single_word_substitution() {
        // 1 mot diffÃ©rent sur 2
        let wer = calculate_wer("hello universe", "hello world");
        assert_eq!(wer, 0.5); // 1 erreur sur 2 mots
    }

    #[test]
    fn test_calculate_wer_word_deletion() {
        // Un mot manquant
        let wer = calculate_wer("hello", "hello world");
        assert_eq!(wer, 0.5); // 1 suppression sur 2 mots
    }

    #[test]
    fn test_calculate_wer_word_insertion() {
        // Un mot ajoutÃ©
        let wer = calculate_wer("hello big world", "hello world");
        assert_eq!(wer, 0.5); // 1 insertion sur 2 mots
    }

    #[test]
    fn test_calculate_wer_multiple_errors() {
        // Plusieurs erreurs
        let wer = calculate_wer("hello big universe", "hello world");
        assert_eq!(wer, 1.0); // 2 erreurs sur 2 mots
    }

    #[test]
    fn test_calculate_wer_completely_wrong() {
        // Tous les mots sont diffÃ©rents
        let wer = calculate_wer("one two three", "four five six");
        assert_eq!(wer, 1.0); // 3 erreurs sur 3 mots
    }

    #[test]
    fn test_calculate_wer_character_difference_in_word() {
        // Une petite diffÃ©rence dans un mot compte comme erreur complÃ¨te au niveau WER
        let wer = calculate_wer("helo world", "hello world");
        assert_eq!(wer, 0.5); // 1 mot diffÃ©rent sur 2
    }

    #[test]
    fn test_calculate_wer_extra_whitespace() {
        // Les espaces multiples sont normalisÃ©s
        let wer = calculate_wer("hello    world", "hello world");
        assert_eq!(wer, 0.0); // MÃªme mots aprÃ¨s normalisation
    }

    #[test]
    fn test_calculate_wer_case_sensitive() {
        // La casse compte au niveau des mots
        let wer = calculate_wer("Hello world", "hello world");
        assert_eq!(wer, 0.5); // 1 mot diffÃ©rent sur 2
    }

    #[test]
    fn test_calculate_wer_more_than_100_percent() {
        // OCR beaucoup plus long que la rÃ©fÃ©rence : WER > 1.0
        let wer = calculate_wer("one two three four five", "one");
        assert_eq!(wer, 4.0); // 4 insertions sur 1 mot de rÃ©fÃ©rence
    }

    #[test]
    fn test_word_levenshtein_distance() {
        let source = vec!["hello", "world"];
        let target = vec!["hello", "world"];
        assert_eq!(word_levenshtein_distance(&source, &target), 0);

        let source = vec!["hello", "big", "world"];
        let target = vec!["hello", "world"];
        assert_eq!(word_levenshtein_distance(&source, &target), 1);

        let source = vec!["hello"];
        let target = vec!["hello", "world"];
        assert_eq!(word_levenshtein_distance(&source, &target), 1);
    }

    #[test]
    fn test_compare_ocr_result_identical_texts() {
        let metrics = compare_ocr_result("hello world", "hello world");
        assert_eq!(metrics.cer, 0.0);
        assert_eq!(metrics.wer, 0.0);
        assert_eq!(metrics.levenshtein_distance, 0);
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 11);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 2);
        assert!(metrics.exact_match);
        assert_eq!(metrics.accuracy(), 1.0);
    }

    #[test]
    fn test_compare_ocr_result_empty_texts() {
        let metrics = compare_ocr_result("", "");
        assert_eq!(metrics.cer, 0.0);
        assert_eq!(metrics.wer, 0.0);
        assert_eq!(metrics.levenshtein_distance, 0);
        assert_eq!(metrics.reference_char_count, 0);
        assert_eq!(metrics.ocr_char_count, 0);
        assert_eq!(metrics.reference_word_count, 0);
        assert_eq!(metrics.ocr_word_count, 0);
        assert!(metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_single_character_error() {
        let metrics = compare_ocr_result("helo world", "hello world");
        assert!((metrics.cer - 1.0 / 11.0).abs() < 0.001); // 1 erreur sur 11 caractÃ¨res
        assert_eq!(metrics.wer, 0.5); // 1 mot diffÃ©rent sur 2
        assert_eq!(metrics.levenshtein_distance, 1);
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 10);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 2);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_multiple_word_errors() {
        let metrics = compare_ocr_result("helo wrld", "hello world");
        assert!((metrics.cer - 2.0 / 11.0).abs() < 0.001); // 2 erreurs sur 11 caractÃ¨res
        assert_eq!(metrics.wer, 1.0); // 2 mots diffÃ©rents sur 2
        assert_eq!(metrics.levenshtein_distance, 2);
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 9);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 2);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_missing_word() {
        let metrics = compare_ocr_result("hello", "hello world");
        assert!((metrics.cer - 6.0 / 11.0).abs() < 0.001); // 6 caractÃ¨res manquants
        assert_eq!(metrics.wer, 0.5); // 1 mot manquant sur 2
        assert_eq!(metrics.levenshtein_distance, 6); // " world" = 6 caractÃ¨res
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 5);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 1);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_extra_word() {
        let metrics = compare_ocr_result("hello big world", "hello world");
        assert!((metrics.cer - 4.0 / 11.0).abs() < 0.001); // 4 caractÃ¨res en trop
        assert_eq!(metrics.wer, 0.5); // 1 mot en trop sur 2
        assert_eq!(metrics.levenshtein_distance, 4); // "big " = 4 caractÃ¨res
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 15);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 3);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_completely_different() {
        let metrics = compare_ocr_result("abc def", "xyz uvw");
        assert!((metrics.cer - 6.0 / 7.0).abs() < 0.001); // 6 erreurs sur 7 caractÃ¨res
        assert_eq!(metrics.wer, 1.0); // 2 mots diffÃ©rents sur 2
        assert_eq!(metrics.levenshtein_distance, 6);
        assert_eq!(metrics.reference_char_count, 7);
        assert_eq!(metrics.ocr_char_count, 7);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 2);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_empty_ocr() {
        let metrics = compare_ocr_result("", "hello world");
        assert_eq!(metrics.cer, 1.0); // 100% d'erreur
        assert_eq!(metrics.wer, 1.0); // 100% d'erreur
        assert_eq!(metrics.levenshtein_distance, 11);
        assert_eq!(metrics.reference_char_count, 11);
        assert_eq!(metrics.ocr_char_count, 0);
        assert_eq!(metrics.reference_word_count, 2);
        assert_eq!(metrics.ocr_word_count, 0);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_empty_reference() {
        let metrics = compare_ocr_result("hello world", "");
        assert_eq!(metrics.cer, 1.0); // 100% d'erreur (par convention)
        assert_eq!(metrics.wer, 1.0); // 100% d'erreur
        assert_eq!(metrics.levenshtein_distance, 11);
        assert_eq!(metrics.reference_char_count, 0);
        assert_eq!(metrics.ocr_char_count, 11);
        assert_eq!(metrics.reference_word_count, 0);
        assert_eq!(metrics.ocr_word_count, 2);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_unicode() {
        let metrics = compare_ocr_result("cafÃ©", "cafÃ©");
        assert_eq!(metrics.cer, 0.0);
        assert_eq!(metrics.wer, 0.0);
        assert_eq!(metrics.levenshtein_distance, 0);
        assert_eq!(metrics.reference_char_count, 4);
        assert_eq!(metrics.ocr_char_count, 4);
        assert!(metrics.exact_match);

        let metrics = compare_ocr_result("cafe", "cafÃ©");
        assert_eq!(metrics.cer, 0.25); // 1 erreur sur 4 caractÃ¨res
        assert_eq!(metrics.wer, 1.0); // 1 mot diffÃ©rent sur 1
        assert_eq!(metrics.levenshtein_distance, 1);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_compare_ocr_result_multiline_text() {
        let reference = "First line\nSecond line\nThird line";
        let ocr = "First line\nSecond line\nThird line";
        let metrics = compare_ocr_result(ocr, reference);
        assert_eq!(metrics.cer, 0.0);
        assert_eq!(metrics.wer, 0.0);
        assert!(metrics.exact_match);
        assert_eq!(metrics.reference_word_count, 6);
    }

    #[test]
    fn test_compare_ocr_result_accuracy() {
        let metrics = compare_ocr_result("hello world", "hello world");
        assert_eq!(metrics.accuracy(), 1.0); // 100% prÃ©cis

        let metrics = compare_ocr_result("helo world", "hello world");
        assert!((metrics.accuracy() - 10.0 / 11.0).abs() < 0.001); // ~90.9% prÃ©cis
    }

    #[test]
    fn test_generate_diff_report_perfect_match() {
        let report = generate_diff_report("hello world", "hello world");

        // VÃ©rifier que le rapport contient les sections clÃ©s
        assert!(report.contains("OCR COMPARISON REPORT"));
        assert!(report.contains("METRICS:"));
        assert!(report.contains("STATISTICS:"));
        assert!(report.contains("COMPARISON:"));
        assert!(report.contains("SUMMARY:"));

        // VÃ©rifier les mÃ©triques
        assert!(report.contains("Character Error Rate (CER): 0.00%"));
        assert!(report.contains("Word Error Rate (WER):      0.00%"));
        assert!(report.contains("Levenshtein Distance:       0"));
        assert!(report.contains("Accuracy:                   100.00%"));

        // VÃ©rifier la qualitÃ©
        assert!(report.contains("Quality: Perfect (exact match)"));
        assert!(report.contains("Match:   Exact"));
    }

    #[test]
    fn test_generate_diff_report_excellent_quality() {
        // Texte long pour avoir < 5% d'erreur : 1 erreur sur 25 caractÃ¨res = 4%
        let reference = "This is a test sentence."; // 24 caractÃ¨res
        let ocr = "This is a tast sentence."; // 1 erreur : e -> a (4.16%)
        let report = generate_diff_report(ocr, reference);

        // VÃ©rifier la classification de qualitÃ© (< 5% erreur = Excellent)
        assert!(report.contains("Quality: Excellent (< 5% error)"));
        assert!(report.contains("Match:   Not exact"));

        // VÃ©rifier que les mÃ©triques sont prÃ©sentes
        assert!(report.contains("Character Error Rate (CER):"));
        assert!(report.contains("Word Error Rate (WER):"));
        assert!(report.contains("Levenshtein Distance:       1"));
    }

    #[test]
    fn test_generate_diff_report_good_quality() {
        // 1 erreur sur 11 caractÃ¨res = ~9% (< 15% = Good)
        let report = generate_diff_report("helo world", "hello world");

        // ~9% d'erreur devrait Ãªtre "Good"
        assert!(report.contains("Quality: Good (< 15% error)"));
        assert!(report.contains("Match:   Not exact"));
    }

    #[test]
    fn test_generate_diff_report_fair_quality() {
        // 2 erreurs sur 11 caractÃ¨res = ~18% (< 30% = Fair)
        let report = generate_diff_report("helo wrld", "hello world");

        // ~18% d'erreur devrait Ãªtre "Fair"
        assert!(report.contains("Quality: Fair (< 30% error)"));
    }

    #[test]
    fn test_generate_diff_report_poor_quality() {
        // Texte trÃ¨s diffÃ©rent (â‰¥ 30% erreur)
        let report = generate_diff_report("abc def", "hello world");

        assert!(report.contains("Quality: Poor (â‰¥ 30% error)"));
        assert!(report.contains("Match:   Not exact"));
    }

    #[test]
    fn test_generate_diff_report_statistics() {
        let report = generate_diff_report("hello world", "hello world");

        // VÃ©rifier les statistiques
        assert!(report.contains("Reference: 11 characters, 2 words"));
        assert!(report.contains("OCR:       11 characters, 2 words"));
    }

    #[test]
    fn test_generate_diff_report_comparison_section() {
        let report = generate_diff_report("hello world", "goodbye world");

        // VÃ©rifier que les deux textes sont affichÃ©s
        assert!(report.contains("Reference: \"goodbye world\""));
        assert!(report.contains("OCR:       \"hello world\""));
    }

    #[test]
    fn test_generate_diff_report_truncation() {
        // CrÃ©er un texte trÃ¨s long pour tester la troncature
        let long_text = "a".repeat(250);
        let report = generate_diff_report(&long_text, &long_text);

        // VÃ©rifier que le texte est tronquÃ©
        assert!(report.contains("... (truncated)"));
        assert!(report.contains("250 characters"));
    }

    #[test]
    fn test_generate_diff_report_empty_texts() {
        let report = generate_diff_report("", "");

        // Devrait Ãªtre un match parfait
        assert!(report.contains("Quality: Perfect (exact match)"));
        assert!(report.contains("Match:   Exact"));
        assert!(report.contains("Reference: 0 characters, 0 words"));
        assert!(report.contains("OCR:       0 characters, 0 words"));
    }

    #[test]
    fn test_generate_diff_report_format() {
        let report = generate_diff_report("test", "test");

        // VÃ©rifier le format avec les bordures
        assert!(report.starts_with("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"));
        assert!(report.ends_with("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"));

        // VÃ©rifier les sections avec tirets
        assert!(report.contains("--------"));
        assert!(report.contains("-----------"));
    }

    // ============================================================
    // Tests avec du texte franÃ§ais
    // ============================================================

    #[test]
    fn test_french_text_perfect_match() {
        let reference = "Bonjour, comment allez-vous aujourd'hui ?";
        let ocr = "Bonjour, comment allez-vous aujourd'hui ?";

        let metrics = compare_ocr_result(ocr, reference);
        assert_eq!(metrics.cer, 0.0);
        assert_eq!(metrics.wer, 0.0);
        assert!(metrics.exact_match);
        assert_eq!(metrics.reference_char_count, 41);
        assert_eq!(metrics.reference_word_count, 5);
    }

    #[test]
    fn test_french_text_with_accents() {
        let reference = "Le cafÃ© est trÃ¨s dÃ©licieux et coÃ»te cher.";
        let ocr = "Le cafe est tres delicieux et coute cher.";

        let metrics = compare_ocr_result(ocr, reference);
        // 4 accents : cafÃ©â†’cafe (Ã©â†’e), trÃ¨sâ†’tres (Ã¨â†’e), dÃ©licieuxâ†’delicieux (Ã©â†’e), coÃ»teâ†’coute (Ã»â†’u)
        assert_eq!(metrics.levenshtein_distance, 4);
        assert!((metrics.cer - 4.0 / 41.0).abs() < 0.001); // ~9.75%
        assert_eq!(metrics.reference_char_count, 41);
        assert_eq!(metrics.ocr_char_count, 41);
        assert!(!metrics.exact_match);
    }

    #[test]
    fn test_french_text_accent_errors_cer() {
        let reference = "Ã©cole";
        let ocr = "ecole";

        let cer = calculate_cer(ocr, reference);
        assert_eq!(cer, 0.2); // 1 erreur sur 5 caractÃ¨res
    }

    #[test]
    fn test_french_text_cedilla() {
        let reference = "Le garÃ§on reÃ§oit un reÃ§u.";
        let ocr = "Le garcon recoit un recu.";

        let metrics = compare_ocr_result(ocr, reference);
        // 3 cÃ©dilles : garÃ§onâ†’garcon, reÃ§oitâ†’recoit, reÃ§uâ†’recu
        assert_eq!(metrics.levenshtein_distance, 3);
        assert_eq!(metrics.reference_char_count, 25);
        assert_eq!(metrics.ocr_char_count, 25);
    }

    #[test]
    fn test_french_text_ligature_oe() {
        let reference = "Un bÅ“uf et un Å“uf dans le cÅ“ur.";
        let ocr = "Un boeuf et un oeuf dans le coeur.";

        let metrics = compare_ocr_result(ocr, reference);
        // 3 ligatures Å“â†’oe (chacune compte comme 1 suppression + 2 insertions = 2 opÃ©rations)
        // En rÃ©alitÃ©: bÅ“ufâ†’boeuf (2), Å“ufâ†’oeuf (2), cÅ“urâ†’coeur (2) = 6 opÃ©rations
        assert_eq!(metrics.levenshtein_distance, 6);
        assert_eq!(metrics.reference_char_count, 31);
        assert_eq!(metrics.ocr_char_count, 34);
    }

    #[test]
    fn test_french_text_apostrophe() {
        let reference = "L'Ã©cole d'Ã©tÃ© qu'il a visitÃ©e.";
        let ocr = "L'ecole d'ete qu'il a visitee.";

        let metrics = compare_ocr_result(ocr, reference);
        // 4 accents : Ã©coleâ†’ecole, Ã©tÃ©â†’ete, visitÃ©eâ†’visitee (2 accents)
        assert_eq!(metrics.levenshtein_distance, 4);
        assert_eq!(metrics.reference_word_count, 5);
        assert_eq!(metrics.reference_char_count, 30);
    }

    #[test]
    fn test_french_text_complex_sentence() {
        let reference = "L'Ã©tÃ© dernier, j'ai visitÃ© la cÃ´te mÃ©diterranÃ©enne.";
        let ocr = "L'ete dernier, j'ai visite la cote mediterraneenne.";

        let metrics = compare_ocr_result(ocr, reference);
        // Accents manquants : Ã©tÃ©â†’ete, visitÃ©â†’visite, cÃ´teâ†’cote, mÃ©diterranÃ©enneâ†’mediterraneenne (2 accents)
        // Total: 6 erreurs
        assert_eq!(metrics.levenshtein_distance, 6);
        assert!((metrics.cer - 6.0 / 51.0).abs() < 0.001); // ~11.76%
        assert_eq!(metrics.reference_char_count, 51);
    }

    #[test]
    fn test_french_generate_report() {
        let reference = "Le dÃ©veloppement logiciel nÃ©cessite de la rigueur.";
        let ocr = "Le developpement logiciel necessite de la rigueur.";

        let report = generate_diff_report(ocr, reference);

        // VÃ©rifier que le rapport est bien gÃ©nÃ©rÃ©
        assert!(report.contains("OCR COMPARISON REPORT"));
        assert!(report.contains("Character Error Rate (CER):"));
        assert!(report.contains("COMPARISON:"));

        // 2 accents : dÃ©veloppementâ†’developpement, nÃ©cessiteâ†’necessite
        // 2 erreurs sur 50 caractÃ¨res = 4% â†’ Excellent
        assert!(report.contains("Quality: Excellent (< 5% error)"));
    }

    #[test]
    fn test_french_multiline() {
        let reference =
            "PremiÃ¨re ligne avec des accents.\nDeuxiÃ¨me ligne trÃ¨s longue.\nTroisiÃ¨me ligne.";
        let ocr = "Premiere ligne avec des accents.\nDeuxieme ligne tres longue.\nTroisieme ligne.";

        let metrics = compare_ocr_result(ocr, reference);
        // 4 accents : PremiÃ¨reâ†’Premiere, DeuxiÃ¨meâ†’Deuxieme, trÃ¨sâ†’tres, TroisiÃ¨meâ†’Troisieme
        assert_eq!(metrics.levenshtein_distance, 4);
        assert_eq!(metrics.reference_word_count, 11);
        assert_eq!(metrics.reference_char_count, 77);
    }

    #[test]
    fn test_french_proper_nouns() {
        let reference = "FranÃ§ois habite Ã  Paris prÃ¨s de l'Ã‰lysÃ©e.";
        let ocr = "Francois habite a Paris pres de l'Elysee.";

        let metrics = compare_ocr_result(ocr, reference);
        // 5 accents : FranÃ§oisâ†’Francois, Ã â†’a, prÃ¨sâ†’pres, Ã‰lysÃ©eâ†’Elysee (2 accents)
        assert_eq!(metrics.levenshtein_distance, 5);
        assert!((metrics.cer - 5.0 / 41.0).abs() < 0.001); // ~12.2%
        assert_eq!(metrics.reference_char_count, 41);
    }
}
